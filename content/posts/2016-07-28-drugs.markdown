---
title: drugs
date: 2016-07-27
---

"Big Pharma" is a term that is often thrown around to describe a handful of private companies whose mission it is to develop and sell pharmaceutical products. Regarding the "selling" portion of their mission statement there is somewhat of a consensus that none of what goes on under that banner is really in our interest. American drug prices are much higher than they are in other countries, rich or poor, for an identical product.["Drug prices in the U.S. are shrouded in mystery, obscured by confidential rebates, multiple middlemen and the strict guarding of trade secrets. But for certain drugs—those paid for by Medicare Part B—prices are public."](http://www.wsj.com/articles/why-the-u-s-pays-more-than-other-countries-for-drugs-1448939481) The data we do have shows, as the same article reports, that 93% of the top 40 brand-name drugs are more expensive, often two or three times more, here than in other developed countries. The reason for that is no mystery (unlike some drug prices): the pharmaceutical industry is essentially a small monopoly and the single largest buyer in the drug market, the U.S. Government (specifically Medicare), is forbidden by law to negotiate drug prices. 

Funnily enough, the Wall Street Journal implicitly acknowledges that this is true: 

>"[Single payer] government systems also are the only large drug buyers in most of these countries, giving them substantial negotiating power. The U.S. market, by contrast, is highly fragmented, with bill payers ranging from employers to insurance companies to federal and state governments.

>Medicare, the largest single U.S. payer for prescription drugs, is by law unable to negotiate pricing. For Medicare Part B, companies report the average price at which they sell medicines to doctors’ offices or to distributors that sell to doctors. By law, Medicare adds 6% to these prices before reimbursing the doctors. Beneficiaries are responsible for 20% of the cost.

>The arrangement means Medicare is essentially forfeiting its buying power, leaving bargaining to doctors’ offices that have little negotiating heft, said Sean Sullivan, dean of the School of Pharmacy at the University of Washington."

A representative of the industry then provides an explanation so unmoored from reality it borders on parody: 

>"The pharmaceutical industry says controls such as those seen in Europe discourage investment in research and deny patients access to some drugs. “The U.S. has a competitive biopharmaceutical marketplace that works to control costs while encouraging the development of new treatments and cures,” said Lori Reilly, an executive at the Pharmaceutical Research and Manufacturers of America, a trade association."

>If U.S. pricing fell to European levels, the industry would almost certainly cut its R&D spending, said Mr. Evans, the health-care analyst. “Does the U.S. subsidize global research? Absolutely, yes,” he said." 

From the first sentence the response is misleading. Europeans are not "denied access to some drugs". European countries do not purchase drugs that do not demonstrate an improvement in quality or cost compared to existing therapeutics. The way I see it, this type of scrutiny is to be expected if one enters a free market. In any case, I don't expect someone who describes the U.S. drug market as "competitive" when the single largest market participant is deliberately excluded to actually know what a market is. Furthermore, if the measuring stick we are going to rely on is access to therapeutics and care then the U.S. will come to that argument without a single leg to stand on. 

The second sentence isn't any better. Controlling costs is precisely what the U.S market does not do and the European market does, as she affirmed in the first. Second, while it is true that European pharmaceutical companies spend less on research they are [demonstrably better at innovation than U.S. firms](http://content.healthaffairs.org/content/early/2009/08/25/hlthaff.28.5.w969.full.pdf+html) and do not spend any money on direct to consumer advertising, something they are prohibited by law from doing. The research already linked demonstrates that dollar for dollar, the Europeans are getting more new drugs and chemical compounds per research dollar than in the U.S. The meta analysis goes on to conclude that "lower European prices seem to be no deterrent to strong research productivity" and even explicitly refutes the idea that Europeans are somehow "free-riding" on American innovation. Not only is the second half of the representative's statement contradictory, it is a complete fabrication. 

Maybe this isn't very surprising and exciting, but it's worth digging a little deeper. Why are the Europeans coming out ahead in research productivity when compared to the United States? We can wade through the evidence. 

*The Measurement Problem* 

First, it's important to define what you mean by efficient. For the Health Affairs investigator cited above, efficiency was defined by the ratio of novel therapeutic innovation to dollars spent on R&D. The simple explanation is that most pharmaceutical research done in the U.S. is not geared to meet this definition of efficiency, it is instead designed to bring new products to market regardless of whether it presents a cost or quality benefit. The technical term among scientists for this type of study is "non-inferiority". A non-inferiority trial does exactly what it says on the tin: it shows that something is at least as good as one other drug on the market, better than placebo, and so on, but it does not try to create something radically new or innovative. 

[The origin of research funding is known to correlate with the type of research being conducted.](http://www.ncbi.nlm.nih.gov/pubmed/26611124) Not only that, but research conducted in industry is not expected to be published and the data is often not made public. Again, this is known and well documented, and some evidence is provided in that paper. In a world where nearly 60% of clinical research is funded by private industry, this is problematic because it means much of the clinical research being conducted is not in the interest of the rapid, free and complete dissemination of ideas nor is it always seriously interested in meaningful innovation. 

But, surely, U.S. pharmaceutical research is still involved, at some level, in the discovery and development of new drugs and treatments? At best, this is half true, if that. [In a staggeringly comprehensive review](http://www.ncbi.nlm.nih.gov/books/NBK83123/), a Columbia University researcher found that not only is public sector research the primary driver behind pharmaceutical and biotechnology innovation, it delivers a far more significant return on investment. It is a short paper worth reading in its entirety. Some highlights: 

>"Philipson and Jena’s (2005) study of HIV-AIDS drugs is another paper that examines the value of increases in health from new medical technologies. Though this study does not explicitly focus on the role of the public sector, it estimates that HIV-AIDS drugs introduced in the 1990s generated a social value of $1.4 trillion, based on the value of the increments to life expectancy created from these drugs (here again, using the estimate of $100,000 per life year). This study is relevant because of the important role of public sector research in the development of HIV‐AIDS drugs, which is observed in several of the empirical studies discussed below.

>A recent paper by Lakdawalla et al (2011) employs a similar approach to assess the benefits from cancer research. The authors find these benefits to be large, estimating the social value of improvements from improvements in life expectancy during the 1988–2000 period to be nearly $2 trillion. The authors note that this compares to investments of about $80 billion dollars in total funding for the National Cancer Institute between 1971 and 2000. As with the HIV studies discussed above, the authors do not calculate a rate-of-return on publicly funded research explicitly, but do argue that the social benefits from cancer research in general far exceed research investments and treatment costs.

>A large share of the benefits in the cancer arena, according to this work, results from better treatments. Lichtenberg (2004) also suggests that new drug development has been extremely important in progress against cancer.8 Public sector research may have been important to the development of these drugs: various studies (Stevens et al. 2011, Chabner and Shoemaker 1989) suggest an important role for the public sector in cancer drug development."

...

>"Surveys of firm R and D managers have also been used to gauge how public sector research affects private sector R and D. Cohen, Nelson, and Walsh (2002) report on the 1994 Carnegie Mellon Survey of Industrial R and D managers, which examined (among other issues) the roles of the public sector in industrial R and D, and channels through which public research affects industrial R and D. This survey is particularly interesting since it has data on both the drug and device sectors, and allows for comparison of these sectors to others. The authors find that the pharmaceutical industry is an outlier in its reliance on public sector R and D. In the pharmaceutical industry, according to respondents, public research was the most important source of new project ideas and contributor to project completion. By contrast, in the medical instruments industry R and D projects less frequently rely on public research than other industries. There are also some differences in the fields of science relied upon across these different industries. Thus the top three fields of science important to R and D projects in the pharmaceutical industry are medicine, biology, and chemistry. In medical instruments sector, the top three fields are medicine, materials science, and biology. Although much of the literature on the effects of public sector funding tend to focus on the NIH, the bulk of funding for materials science R and D comes from other agencies (including the National Science Foundation, Department of Energy, and the Department of Defense)."

...

>"Strikingly, the authors also show that virtually all the important vaccines introduced over the past quarter century came from the public sector. The authors also show broad correlations between NIH Institute budgets and the therapeutic classes where there are numerous public-sector based drugs, similar in spirit to econometric analyses we will review below."

I'd be overstepping if I quoted any more. In spite of being overshadowed by the private sector in recent years, investment in public sector research leads the way in innovations critical to actually improving human health and lowering costs. Of course, this isn't surprising. The data fits very well into the verified model of how essentially all 21st century private technology firms operate. Namely...

*Socialization of cost, privatization of profit* 

So the research that is actually driving innovation comes from the public sector. This is not unique to the biomedical industries. The internet and all technology that relies on it is a perfect example of a totally publically developed project that has been, in essence, handed over to private industry, and, worse, primarily to another small monopoly, the tele-communications industry. The socialization of cost and the privatization of profit is not a novel concept; I'm not so clever as that. It would even be a cliché if it was not such an obvious modus operandi. 

As evidence: the remedy proposed in the Health Affairs paper.  

>"Jayadev  and Stiglitz also recommend having clinical trials independently run and paid for by a public body such as the National Institutes of Health so that they can be designed to measure comparative advantages and risks over existing treatments. Publicly funded trials would also reduce cost and risk for pharmaceutical companies and increase  competition  from  smaller  firms  by  lowering  the  high  cost  barrier  that company-funded trials pose."

I don't think you can get more explicit than that. If demanding increased investment in publicly funded clinical trials to both remedy the structural problems of privately funded clinical research - namely, that most of it is not designed to measure comparative advantages and risks over existing treatments - and reduce the cost and risk to pharmaceutical companies who stand to make all of the profit *is not* obviously an endorsement of the socialization of cost and the privatization of profit then I don't know what is. That is without even getting into the fact that to conduct any clinical research to begin with you need to have patients, patients whose care costs are not only themselves socialized (remember, Medicare is the largest payer in our healthcare system even if it is not the only one) but who, when participating in clinical trials, are often being cared for at academic and teaching institutions created and supported almost in their entirety by the public. 

It is disingenous to suggest that pharmaceutical companies do *nothing*. They are still responsible for the mass production and distribution of drugs and therapeutics, even if the chemicals, techniques, and technologies were themselves first discovered by the public sector, and they fund the majority of late-stage clinical trials (that is, human trials). Further, it is not as if all privately funded research is useless, quite the opposite. In fact, if a company has good reason to believe its product is, in fact, superior there is a great chance that a good deal of resources will go into performing an incredibly competent, powerful, and rigorous clinical trial. 

The question to be asking is: What are *they* doing, that the public sector couldn't? 

Well, there's some evidence for that too. A significant activity unique to the private sector is the obstruction of academic responsibilities, namely the free and transparent dissemination of information, in a deliberate attempt to evade market forces all at immense cost to the public.

[The instructive case](http://docdro.id/vnwQP52): a two-year long episode in 1997 where the Boots pharmaceutical company attempted to suppress the publication of data which showed that their drug, Synthroid, was equivalent to three competitors. Synthroid dominated a 600 million dollar per year market and the company was on the verge of being acquired for billions of dollars when the UCSF trial was set to be published. Replacing Synthroid with an equivalent product threatened to save 356 million dollars per year in healthcare costs, a more than 50% market reduction. Eventually, thanks to FDA pressure (in other words, thanks to an investigation financed on the public dime), the results were made public and Boots backed down from its position. Around 5% of 2100 life science researchers surveyed reported a similar delay in publication (at least 6 months) to slow the dissemination of undesired results. Again, all of this comes at the public cost in the form of literal money, inefficient or dangerous delivery of care, at a professional cost to academics who depend on publication for their own credibility and career prospects, and so on. 

After just a glance at the evidence, the response from industry in the Wall Street Journal only appears more vulgar. Drug prices have nothing to do with competitive or free markets, nothing to do with innovation, the commitments to innovation that do exist are only really commitments if it is in the company's best interest, and, worst of all, even taking all of this into account, it is somehow still consciable for academics to recommend that the public increase its subsidy of the private sector to "reduce cost and risk for pharmaceutical companies". 

Furthermore, this methodology is not unique to drugs. Diagnostic technologies and protocols work in much the same way. Their development and origination is financed almost entirely by the public, until a (often inferior and mass producible but sufficiently sensitive) test or diagnostic procedure is able to be patented and sold by a private medical diagnostics company. There is no "R&D" going on at the level of medical diagnostics companies, whose margins are too small to fund the kinds of trials that drug and medical technology manufacturers are capable of. What is actually going on is a lot of "D" and almost no "R". The "R" still happens at the public sector, and the development teams at medical diagnostic companies are primarily concerned with using existing knowledge to create a profitable test in order to stake out territory in the market. Again, this "market" is by no means free. The territory in medical diagnostics is heavily protected on a "first-come" basis since it is heavily dependant on the protection of intellectual property which prevents anyone from competing in any particular territory (say, a test for a particular disease or condition) without a prohibitive amount of investment. I learned this personally in a Q&A session with the head of Research and Development for a medical diagnostics firm here on campus. However, don't take my word for it. I'm certain that even a shallow analysis, such as the one started here for the pharmaceutical industry, would reveal that these principles are generally true for every single firm in the sector across the board. 

It is also worth mentioning that even if you are totally fine with how private industry is profiting in total isolation from public labor and resources that a lot of the profit made by medical diagnostics companies is due exclusively to the fact that patient data is treated as proprietary information. How medical data is being used and abused to serve private interests rather than the public good is a topic for another day. 

As long as this narrative continues, how are we supposed to convince the public to trust in our biomedical research establishment which, private or public, is nevertheless made up of caring peope dedicated to improving human health? Dr. Catherine DeAngelis writing in [JAMA](http://jama.jamanetwork.com/article.aspx?articleid=193220) summed it up: 

"Without trust, medical research is doomed."



